---
title: "Balcewicz HW 3"
author: "Katie Balcewicz"
date: "1/30/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Univariate Assignment

Read in tree data, metadata can be found in: ./data/tree_metadata.txt
```{r}
trees = read.csv("https://raw.githubusercontent.com/dmcglinn/quant_methods/gh-pages/data/treedata_subset.csv", 
                 header = TRUE)
acer = subset(trees, species == "Acer rubrum")
abies = subset(trees, species == "Abies fraseri")
```

## 1. Exploratory analysis
```{r}
str(acer)
str(abies)
```
```{r}
hist(acer$cover)
hist(abies$cover)
```

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor=3, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) 
        cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor)
}
pairs(acer[,c("cover", "elev", "tci", "streamdist", "disturb", "beers")], 
      lower.panel = panel.smooth, upper.panel = panel.cor)
pairs(abies[,c("cover", "elev", "tci", "streamdist", "disturb", "beers")], 
      lower.panel = panel.smooth, upper.panel = panel.cor)
```



```{r}
lm.acer = lm(cover ~ elev + tci + streamdist + disturb + beers, data = acer)
summary(lm.acer)
lm.abies = lm(cover ~ elev + tci + streamdist + disturb + beers, data = abies)
summary(lm.abies)
```

```{r}
library(car)
Anova(lm.acer, type = 3)
Anova(lm.abies, type = 3)
```
 The p-values generate by the Anova function are the same as those generated by the lm function.

```{r}
library(MASS)
step.acer =  stepAIC(lm.acer)
step.abies = stepAIC(lm.abies)
```

```{r}
summary(step.acer)
summary(step.abies)
```

```{r}
plot(step.acer)
plot(step.abies)
```

The Acer rubrum model has a multiple r-squared value of 0.04174, indicating that only 4.174% of the variation in cover can be explained by the explanatory variables. The variables that were included in the stepwise regression, and thus the most important variables, are elev, tci, streamdist, and beers. Model diagnostics plots indicate that there are no major violations of the OLS assumptions. 

The Abies fraseri model has a multiple r-squared value of 0.5204, indicating that 52.04% of the variation in cover can be explained by the explanatory variables. The variables that were included in the stepwise regression, and thus the most important variables, are elev and tci. Model diagnostics plots indicate that there are no major violatuins of the OLS assumptions.

Between the two models, the variance in Abies fraseri cover is much better explained by the data. This is possibly because it is a habitat specialist and there is less variation in the range of habitats for which the model must make predictions. 
 
## 2. General Linear Model (GLM) with a Poisson error term 
```{r}
acer_glm = glm(cover ~ elev + tci + streamdist + beers , data = acer, 
                family = 'poisson')
abies_glm = glm(cover ~ elev + tci, data = abies, family = 'poisson')

pseudo_r2 = function(glm_mod) {
     1 -  glm_mod$deviance / glm_mod$null.deviance
}

acer_r2 = pseudo_r2(acer_glm)
acer_r2

abies_r2 = pseudo_r2(abies_glm)
abies_r2
```

```{r}
anova(step.acer, acer_glm)
anova(step.abies, abies_glm)
```

Changing the error distribution greatly reduced the residual sum of squares errors for both models. For the Acer model, it reduded from 2837.66 to 625.28, a difference of 2212.4. For the Abies model, it reduced from 105.99 to 20.055, a reduction of 85.935.

## 3. Plain english summary
    
The cover of Acer rubrum and Abies fraseri trees can be predicted using orinary least squares regression and more accurately predicted using a generalized linear model with a poisson error term, that is, changing the structure of the model so that it better fits the format of the data. The predictions for Abies fraseri, a habitat specialist with less variation in its predictor and response variables, are more accurate than those for Acer rubrum, a habitat generalist with more variation in its predictor and response variables. It is easier to build a model that predicts for a smaller range of data than a wider range.

## 4. Examine the behavior of the function step()
```{r}
step.abies = stepAIC(lm.abies)
```

The step.aic() function starts with the full model and reports the AIC. It then tests each of the models that result from removing a single variable and removing no variables and reports the AIC from each individual model. It chooses the model that had the biggest drop in AIC (lower is better) and repeats. Again, it tests each of the models that result from removing one of the single remaining variables and no variables and chooses the model that has the largest frop in AIC. This repeats until the model that results from removing no variables (the <none> row) is chosen. This is the final model that is returned by the function.

## 5. Develop a model for the number of species in each site
```{r, message=FALSE, warning = FALSE}
library(plyr); library(dplyr);
unique.plot = ddply(trees, .(plotID), summarise, unique_species = length(unique(spcode)),
                                                 elev = first(elev),
                                                 tci = first(tci),
                                                 streamdist = first(streamdist),
                                                 disturb = first(disturb),
                                                 beers = first(beers))
head(unique.plot, 5)
```

```{r}
unique_glm = glm(unique_species ~ elev + tci + streamdist + disturb + beers , 
               data = unique.plot, family = 'poisson')
summary(unique_glm)
unique_r2 = pseudo_r2(unique_glm)
unique_r2
```

```{r}
step_unique = stepAIC(unique_glm)
```

